Whats is Docker :
Docker is a Containerization Platform which packages your application and all its dependencies together in the form of containers as to ensure that your application works seamlessly in any environment be it dev,qa,prod

Docker is an open-source platform that makes it easy to build, ship, and run distributed applications. With Docker, you can create lightweight, portable, and self-sufficient containers that can run on any system.

What is Docker File:
a text file contains to build the docker images including os,environment variables,application code file locations network ports and any other components

What is Docker Image:
1: Docker image is a Read only binary template(Like Snapshots) used to build containers
2: Images also contains the metadata that describe the containers capabilities and needs
3: Using docker build command along with docker file we can create a image
4: docker images can't execute by themselves and cannot run or start it is just blueprint for creating containers
5: run the docker images using docker run and image name/id
6: when we pass that command to docker client that docker client pass that to the docker daemon then docker daemon will create container for that image
7: push that image to repository using docker push command

Image: Contains Application Code , Dependencies, Os where the application should Run
It is a collection of read only layers.These layers are loosely coupled
- Image is Static

What is Docker Container:
1: Container is a Runnable instance of the Image
2: Image cannot run by themselves and build an container
3: Container is a light weight and platform independent of way of running your applications
4: Every container is isolated but access to resources on another host or container can be allowed with the help of docker networking
5: A container is volatile/ it means whenever you remove or kills the container then all of it data will be lost form it if you want to persist the container data use docker volumes concept
6: containers only have access to resources that are defined in the image unless additional access is defined when building the image into a container
7: all docker images become docker containers when they run on the docker engine

8: Container is light weight portable
9: A container is a standard unit of software that packages up code and all its dependencies so the application runs quickly and reliably from one computing
10: It is a Run Time Environment for the application irrespective of OS
11: Portable and Self-Describing.
12: Container is a executing environment with configurable isolation and resource limitations
13: Containers are light weight in nature

Resources Limitations : Namespaces,Resources Limitations, Mounts etc ..

Why Containers are needed:
First Thing Run at Any environment
Encapsulate the Application code and its all dependencies
Self-describing and portable
It can run without any extra dependencies

Difference Between VMs and Containers :
VM:
VM is Hardware Virtualization
VM should contain full operating system with individual machine
VM is high secure
VM is Multiple Machines each with its own guest OS

Containers:
Light weight in nature
Minimal OS is required
Portable
Isolation of VMs
Multiple Instances of Single Application

Describe a Process of Containerization of Application:
Write a Dockerfile
Build the image with that file
Push the image to repository
Run the image to create a container

docker run exec -it <container-name> bash

How to Ensure that docker container start when the docker host restarts:
1: Using Restart policies in docker compose
version: '3'
services:
  your_service_name:
    image: your_image_name
    restart: always
2: Running the container using docker run -d --restart always -p 9090:8080 image-name/id

What is Docker compose:
1: When we are having multiple containers to our project we can use docker compose where we can have volume mounts /networks
version:
network:
  name:
volumes:
  name:
services:
  volumes:
  networks

docker-compose up -d

Difference between Image and Container:
image is read only
container is light weight portable
How to Configure Private Repository:
1: Create a Repository in
/etc/docker/daemon.json --> add the ip address/

Types of Networks in Docker:
1: Bridge Network Default &
2: Host Network
3: Overlay Network 2
4: None Network
5: Macvlan Network

What is Bridge Networking:
1: Bridge networking is the default networking mode in Docker. When you create a Docker container without specifying a network, it is connected to the default bridge network.

Use Case:
Suitable for standalone applications where containers need to communicate with each other on the same host.

What is Host Networking:
1: In host networking, a container shares the network namespace with the Docker host. The container bypasses Docker's network isolation and directly uses the host's network stack
Use Case:
Useful when performance is critical, and you want the container to have direct access to the host's network stack.
Note: It may compromise container isolation and security.

What is Overlay Networking:
1: Overlay networking used when we need to interact between the containers between multiple hosts

Use Case:
Ideal for applications that are distributed across multiple hosts in a Swarm cluster.
Provides a unified network view for services running on different hosts.

Scenarios:
Container with jenkins and new joine restarts the container and we cant see any data:

1: First Check the logs for container
2: Mount the jenkins directory to the Volumes var/jenkins_home directory to the Volumes to save the data
3: Ensure that permissions and ownership for that user to the directory where we mounted the jenkins data
4: Check the restart policy
5: Check the Configuration like env, ip address etc..
6: it might me using old/deprecated jenkins image
7: it might be causing due to recently added plugins

# Most of the times when we start the containers and it does not start correctly how to trouble shoot:

1: Check the docker logs: docker logs <container-id>
2: Check the container status: docker ps -a
3: Inspect Container configuration: docker inspect <container-id> # Like environment variables, volumes, and network configurations.
4: Check the resources constraints: docker stats <container-id> # Like CPU memory etc
5: Check the events: docker events
6: Verify the Docker version: docker --version
7: Check the Network setup: docker network inspect <container-id> # Networks Ip Address etc
8: Check the port conflicts: docker port <container-id> # Like Port Conflicts
9: Test with simple image: docker run hello-world
10: update the docker images: docker pull <image-name>
11: Check for Container Dependencies:
12: Recreate the container:

# How do you secure the docker containers:

1: Use the Official images:
2: Regularly update the images: docker pull <image_name>:<tag>
3: Minimize Container Size: Avoid adding unnecessary files to the container
4: Avoid Running as Root: USER nonrootuser
5: Use Docker Content Trust (DCT): export DOCKER_CONTENT_TRUST=1
6: Implement Resource Constraints: docker run --cpu-shares=512 --memory=512m -d <image_name>
7: Network Segmentation: docker network create my_network
8: Expose Only Necessary Ports:
9: Monitor Container Activity: Docker Bench
10: Limit Container Capabilities: --cap-drop=ALL --cap-add=NET_BIND_SERVICE
11: Use Docker Security Scanning Tools: Trivy
12: Limit Volume Mounts:
13: Apply SELinux/AppArmor Profiles:
14: Secure Docker Daemon:
15: Use Docker Secrets for Sensitive Data:
16: Regular Security Audits:
17: Educate Development Teams:

Performance, Scalability and Security
# Can you describe canary deployment with docker containers:

Explain a Sample Docker file on each language:
1: Js Application
2: Java application
3: Go Lang Application
4: Python
5: SpringBoot
6: C#
7: MySQL
8: MongoDB

Can we launch Linux Containers on Windows and Vice Versa:
No We cannot launch

What is OnBuild Instruction:
The on build instruction adds to the image trigger instruction to be executed at a later time when the image is used as the base for another build

Commands executed on top of parent image is called OnBuild Instructions

Parent (UpStream Build Image)
Child (Down Stream Build Image)

What is the use of Docker Ignore File:
By Default we will set the directory as current .
The request will send to Docker daemon it will take all the files to remove all unwanted files we use docker ignore files

1: To remove all Zip/tar files
2: To remove all .git files
3: To remove .tf-vars etc..

Docker Delete all the Stopped Containers:
docker rm -f $(docker ps -a)
docker container prune

is it good to use docker compose in production:
No it is not good

How to Parameterize base image tag:
using the ARG Instruction we can pass the OS Version
Parameterize the image version

Building Docker file in Large files directory good practice:
No It is not a good practice

Topics Discussed:
Docker Introduction: Session 51

Where pulled Image are stored:
- /var/lib/docker/
Docker Image SHA:
- Full SHA256 code where we can get the image using HashCode
- it is also called Docker Dangling Image
- docker history <image-name>.

Architecture of Docker Images:
- docker manifest inspect <image-name>

Tagging an image:
- docker tag
How to check the instructions that were used to build image:
- docker image history <image-name>

Why Containers are Relatively Small:
- Images don't contain kernel. They share and access the one used by the host on which they are running

Virtualization --> Logical isolation of one physical systems into multiple systems

Image is Static and immutable
Container is Dynamic it can be runnable and mutable

docker pull
docker create
docker start

docker run = pull + Create + Start

docker port forwarding

Docker FROM
Docker RUN :
    Run instruction will run at the time of image creation
    It is used to install all packages required to build an image and run the container

Docker CMD :
    it is to run the container, it will run at image creation.
    the instruction is used to RUN the container with given Instructions
    Can be over ridden

Docker EntryPoint:
    This will fixed run time environment to the container
    cannot be overridden

Labels Instruction: Session 52:

    LABEL : Giving key value pairs to the docker file
    labels are the key-value pairs that represents the tags for images not for the containers
    images can be filtered based on the labels like
    docker build -t <image-name> .
    docker images --filter labels=key=value
    docker inspect <image-id> --> This can inspect all the details about the images

Standard input : this is the file handle that your process reads to get information from you.

Standard output :  your process writes conventional output to this file handle.

Standard error : your process writes diagnostic output to this file handle.

Expose Instruction :
    we can instruct the container builder to set the port for the conatiner based on the expose instruction
    EXPOSE 80/tcp
    expose will not adding any functionalities this is just instruction for conatiner builder

ENV Instruction : Environment Variables
    Configuration is supplied Through Environment Variables
    we can add environment variables to the container
    it is as same as Labels but env will be used in container but lables will used for filtering

Docker Copy:
    Copy The content from local to Image/conatiner

    COPY /source/file/path  /destination/path

Docker ADD :
    This command will copy the content from local to image/container
    This also copy the content from internet
    This also copy the content by unzipping automatically
    ADD /source/file/path  /destination/path
    ADD http://source.file/url  /destination/path

Docker CMD:
    CMD ["executable","param1","param2"]
Docker save:
    standard output
    Save one or more images to a tar archive (streamed to STDOUT by default)
Docker Load:
    Load an image from a tar archive

Docker Can be used in production

Docker Stats: docker statistics used to To monitor cpu and memory the docker in production

Docker Events: is used to monitor the eveents take place in the docker daemon

Docker Compose: docker compose will always run in the dependency order
dependency :
    depends_on
    links
    volumes_from
Docker Cycle Management:
    stop
    pause
    run

Docker Session : 53

Docker USER Instructions:
    With user instruction we can give the minimal previlages to the root access
    After Creating the user, every instruction after user will be done in that user only.

Docker WorkDirectory:
    Instead of cd command in normal linux we used workdir instruction to set the workdirectory where we should save the file
    By default after workdirectory instruction every thing will run on that workdir.

Docker Arg Commands:
    It will supply the variables at the build time but not supply at container run time
    to supply arguments at run time we need to use it like
    env var1=arg1
    Arg can be used as a first instruction to supply the os version to from Instruction
    docker build -t <name-of image> --build-arg version=9 .

 ARG Vs ENV:
    Arg: will work in only build time of image
    ENV: will work on both at build time as well as RUN time

    ARG name
    ARG COURSE

    ENV variable1 =${name: -hair }
    ENV variable2 = ${COURSE: - ped }

    docker build -t arg:v1 . --build-arg name=simple
    --build-arg course=devops

Docker OnBuild :
    On Build will work/execute/create at container run time not at image build time
    We need to have file in our workspace while using the On build Instruction

Docker Is Easy Portable:
AMI --> Heavy Size, Full Operating System, Mutable, Immovable,
docker-compose up -d
docker-compose down -d

Data will be removed once the container is removed hence we need to store data somewhere there docker volumes will come into existence

Volumes : Docker Volumes
    Docker is Ephemeral In nature
    Databases --> RDBMS,NoSQL,Redis,MQ,MySQL
Docker has two types of Volumes:

1) Docker Named Volumes
2) Docker UnNamed Volumes

Volumes: -v <host-path>:<container-path>
Docker is storing temporary volumes in the directory -->/var/lib/docker/overlay2 --> temporary volumes
- CPU
- Memory
- Storage
- RAM

1: Bind Mounts:
2: Volumes:

UnNamed Volumes: (Bind Mounting/Bind Volume)
Create a Directory and map it with the docker containers to store data
We have to manage the directory
docker run -d -v <host_path>:<container_path> <image_name> /bin/bash

Named Volumes:
- Using Docker CLI we can Manage the volume and attach to Containers
- Mount Th volume to containers
- Docker Containers in same commands
- Volume mounts and Docker -v will do same

Docker Should manage these volumes
Everything is managed by docker commands
docker run -d -v <volume_name>:/data <image_name> /bin/bash

docker inspect <container-id> --.
docker volume inspect <container-id>
docker volumes ls --> list down all the volumes

StateFul Applications:
Mongodb
MySQL
Redis
RabbitMQ
docker run -p <host-port>:<container-port> -v <host volume path>:<container-volume-path> --name <container name>

Docker Compose File:
*****
volumes:
- source: rabbitmq
  target: /var/lib/rabbitmq
  type: volume
*****

Docker Best Practices:

1) Creating Named Volumes is Best Practices
2) Create Networking is best Practices
3) Use Official Images
4) Try To reduce the memory using multistage building etc..
5) By Using Office Alpine images memory will be reduces to almost 100 perecnt
6) MultiStage Builds Mention
7) Use Distroless Images
8) Use Docker Security Scanning

Docker Session - 56

Docker Architecture:
    Docker CLI --> Where we write Docker Commands
    Docker Daemon --> Where all The containers are managed using daemon
    Docker HUB --> Where Docker Images are build and pushed for public use

Docker Layers:
    Once we create the image we cannot change image
    docker image is immutable and static in nature

    Each Instruction in the Docker file is Called the Docker layer.

    Each instruction will create one image and one mini container will create.

    There is one component will be there to run and build everything that is docker engine

    One layer will create one image and one container on top of each container the next instructions will be run when the instruction moves to next then previous mini container created by Docker Engine will be destroyed.


Docker is Located in :
    /var/lib/docker/ : All information related to docker will be stored here
    /opt/containerd/ : Is the place where container daemon is located
    /lib/.systemd/docker.service : is the place docker service is located

docker push :
    url/username/image-name:version
    docker tag web:v1 docker-hub.io/hari9397/web-component:v1
    "docker push docker-hub.io/hari9397/web-component:v1"

docker commit:
    creates a new images to a running containers changes
    if you have changed something in the running container then docker commit will add new changes and creates new images out of it

docker history <image-name> :
    it will show the docker image histroy how many time the image got changed

docker digest:
    Digest is content addressable identifier where it can filter the images based on the content even if it has the same name and tags

docker manifest inspect <image-name> :
    client calls the image name
    it will go the client then checks in the local if exits it will pull else it will go to the registry from ther eit will pulled
    each manifest parsed layers will get ids
    from that ids it will get pulled

docker diff <containerid> :
    it will list down all the files added or copied to the container filesystem
registry configurations:
    /etc/containers/registries.conf

Docker Disadvantages:
    1) What will Happen if Docker Server is Down
    2) What happens if you suddenly get more traffic
    3) How to balance the load if you have multiple containers
    4) Self Healing --> what happens when the correct resources are not reached
    5) what about Secrets and Configs --> SSM Parameters are Stored

Container Orchestration:
    Orchestra Means --> Where one Person can manages the different persons to get the work done

    One Person Giving the Instructions to another persons

    When containers are running we need to manage those containers

    Docker Run --> Creating Container Out Of Image
    Image --> Physical File Static,Immutable, Builder File

Kubernetes: For Better Networking,Storage Solutions and Security instead of Docker Swarm.

How will you monitor docker in production:
using docker stats --> docker statistics

is it a good practice to run docker compose in production:
yes using docker compose in production is the best practical application of docker compose

What is namespace in Docker:
Namespace is the linux feature and one of the most important concepts of containers
Namespace adds a layer of isolation in containers

1: PID process id namespaces
2: Mount
3: IPC
4: User
5: Network
6: cgroup

How you can use container edit it and update it:
docker commit <container-id> <username/image-name>

docker prune : used to delete unused images containers in any namespace all stopped

Where all do you think docker is being used:
1: Simplifying configuration
2: Code pipeline management
3: Developer Productivity
4: Application Isolation
5: Debugging Capabilities
6: Multi-Tenancy
7: Rapid Deployment

Docker states:
1: create
2: start
3: pause
4: unpause
5: restarted
6: exited
7: dead























